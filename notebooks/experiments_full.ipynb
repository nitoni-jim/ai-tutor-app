{"nbformat":4,"nbformat_minor":5,"metadata":{},"cells":[{"cell_type":"markdown","metadata":{},"source":["# AI Tutor App – Full Pipeline Notebook\n\nThis notebook demonstrates a full prototype workflow for the **AI-Tutor-App** project:\n\n1. Text cleaning (general + math-aware)\n2. Generate embeddings (sentence-transformers) with a deterministic fallback\n3. Build a simple file-backed vector store\n4. Perform semantic retrieval\n5. Produce a placeholder generated explanation (RAG-style)\n\n**Notes for reviewers:** this notebook uses deterministic fallbacks if `sentence-transformers` is unavailable so the retrieval flow can be reviewed without heavy dependencies."]},{"cell_type":"markdown","metadata":{},"source":["## Setup\n\nBefore running cells that call the embedding model, install dependencies locally:\n\n```\npip install -r ../requirements.txt\n```\n\nIf `sentence-transformers` is not available, the notebook will fall back to deterministic vectors."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["import os,json\nimport numpy as np\nfrom preprocessing.text_cleaning import clean_text\nfrom preprocessing.math_cleaning import normalize_math\n\ndef print_retrieved(docs):\n    for i,(txt,score) in enumerate(docs,1):\n        print(f\"{i}. (score={score:.3f}) {txt[:300]}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Sample data (raw exam-style questions)\n\nWe simulate a small question bank for cleaning and embedding."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["raw_texts=[\n\"Solve: 2×(3 + 4) = ?\",\n\"Find the LCM of 12 and 18.\",\n\"Differentiate: d/dx x^2.\",\n\"What is the area of a circle with radius 7 cm?\",\n\"Simplify: (x^2 - 1)/(x - 1)\"\n]\ncleaned_texts=[clean_text(t) for t in raw_texts]\nmath_normalized_texts=[normalize_math(t) for t in raw_texts]\nprint(\"Cleaned samples:\")\nfor ct in cleaned_texts:\n    print('-',ct)"]},{"cell_type":"markdown","metadata":{},"source":["## Embedding generation\n\nUse `sentence-transformers` if available, otherwise fall back to deterministic random vectors."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["def try_load_sentence_transformer(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n    try:\n        from sentence_transformers import SentenceTransformer\n        return SentenceTransformer(model_name)\n    except Exception as e:\n        print(\"Warning: sentence-transformers not available:\",e)\n        return None\n\ndef embed_texts_safe(texts,model=None,dim_fallback=384,seed=42):\n    if model is not None:\n        try:\n            return np.array(model.encode(texts,show_progress_bar=False))\n        except Exception as e:\n            print(\"Model failed, falling back:\",e)\n    rng=np.random.default_rng(seed)\n    return rng.standard_normal((len(texts),dim_fallback))\n\n_model=try_load_sentence_transformer()\nembeddings=embed_texts_safe(cleaned_texts,model=_model)\nprint(\"Embeddings shape:\",embeddings.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Save embeddings + vector store\n\nStore vectors as `.npy` and texts as JSON."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["def save_vector_store(vectors,texts,base_path=\"./data/metadata/vector_store\"):\n    os.makedirs(os.path.dirname(base_path),exist_ok=True)\n    np.save(base_path+\".npy\",np.array(vectors))\n    with open(base_path+\"_texts.json\",\"w\",encoding=\"utf-8\") as f:\n        json.dump(list(texts),f,indent=2)\n\ndef load_vector_store(base_path=\"./data/metadata/vector_store\"):\n    vectors=np.load(base_path+\".npy\")\n    with open(base_path+\"_texts.json\",\"r\",encoding=\"utf-8\") as f:\n        texts=json.load(f)\n    return np.array(vectors),texts\n\nstore_path=\"./data/metadata/vector_store\"\nsave_vector_store(embeddings,cleaned_texts,store_path)\nvectors,texts=load_vector_store(store_path)\nprint(\"Loaded vectors:\",vectors.shape,\"Loaded texts:\",len(texts))"]},{"cell_type":"markdown","metadata":{},"source":["## Retriever (Cosine Similarity)"]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["def cosine_similarity_vec(a,b):\n    a=np.asarray(a);b=np.asarray(b)\n    denom=(np.linalg.norm(a)*np.linalg.norm(b))+1e-12\n    return float(np.dot(a,b)/denom)\n\nclass SimpleRetriever:\n    def __init__(self,vectors,texts):\n        self.vectors=np.asarray(vectors)\n        self.texts=list(texts)\n    def retrieve(self,query_vec,top_k=5):\n        sims=np.dot(self.vectors,query_vec)/(np.linalg.norm(self.vectors,axis=1)*(np.linalg.norm(query_vec)+1e-12))\n        idxs=np.argsort(-sims)[:top_k]\n        return [(self.texts[int(i)],float(sims[int(i)])) for i in idxs]\n\nretriever=SimpleRetriever(vectors,texts)\nquery=\"What is the least common multiple of 12 and 18?\"\nq_emb=embed_texts_safe([query],model=_model)[0]\ndocs=retriever.retrieve(q_emb,top_k=3)\nprint(\"Top retrieved:\")\nprint_retrieved(docs)"]},{"cell_type":"markdown","metadata":{},"source":["## Generation (placeholder)\n\nThis notebook uses a placeholder generator that concatenates retrieved contexts and returns a short explanation. Replace with an LLM call for production."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["def generate_placeholder_explanation(query,retrieved_docs):\n    context=\"\\n\\n\".join([f\"- {d[:300]}\" for d,_ in retrieved_docs])\n    explanation=f\"Context:\\n{context}\\n\\nExplanation:\\n(This is a placeholder. Replace with LLM output for production.)\"\n    return explanation\n\nprint(generate_placeholder_explanation(query,docs))"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation notes\n\nFor retrieval: use Recall@k and MRR. For generation quality: human eval or BLEU/ROUGE when reference answers exist."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["try:\n    from evaluation.metrics import recall_at_k,retrieval_mrr\n    ex_true=[1,0,2]\n    ex_rank=[[1,2,0],[0,2,1],[2,0,1]]\n    print(\"Recall@2 demo:\",recall_at_k(ex_true,ex_rank,k=2))\n    print(\"MRR demo:\",retrieval_mrr(ex_true,ex_rank))\nexcept Exception as e:\n    print(\"Evaluation import failed:\",e)"]},{"cell_type":"markdown","metadata":{},"source":["## Command-line demo script note\n\nYou can run `run_demo.py` from the repo root to reproduce the flow."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["demo_code='''from embeddings.generate_embeddings import load_model, embed_texts\nfrom embeddings.vector_store import save_vectors, load_vectors\nfrom rag.retriever import Retriever\nfrom rag.generator import generate_explanation\nfrom preprocessing.text_cleaning import clean_text\nfrom preprocessing.math_cleaning import normalize_math\n\ntexts=[\"Solve: 2x + 5 = 11.\",\"Find the LCM of 12 and 18.\"]\nmodel=None\ntry:\n    model=load_model()\n    embs=embed_texts([clean_text(t) for t in texts],model)\nexcept:\n    import numpy as _np\n    rng=_np.random.default_rng(42)\n    embs=rng.standard_normal((len(texts),384))\n\nsave_vectors(embs,[clean_text(t) for t in texts],'./data/metadata/vector_store')\nprint(\"Run demo complete.\")'''\nopen('../run_demo.py','w',encoding='utf-8').write(demo_code)\nprint(\"Wrote ../run_demo.py\")"]},{"cell_type":"markdown","metadata":{},"source":["## Closing notes & citation\n\n```bibtex\n@misc{jimogbolo2025aitutor,\n  title={AI-Tutor-App: An Intelligent Tutoring System for WAEC/NECO/JAMB Exams},\n  author={Nitoni Jim-Ogbolo},\n  year={2025},\n  url={https://github.com/nitoni-jim/ai-tutor-app}\n}\n```"]}]}
